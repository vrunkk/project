{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e47b6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import regex as re\n",
    "import emoji\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import keras\n",
    "from keras.regularizers import l1, l2\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification, BertForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eedbffd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going through depression open this thread</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fivebalanceusa good afternoon would honored to...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fkin depressed gonna feeling like this</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when have anxiety every pleasure guilty pleasure</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sorry canxexxt talk right ixexxm doing girl sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>that frequently</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>counterargument krugman predicted great depres...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>think dignity overrated that status doled limi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>cant make depression disappear over night sure...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>bwhen depression strikes itll weak your bonent...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    \n",
       "0             going through depression open this thread      1 NaN\n",
       "1     fivebalanceusa good afternoon would honored to...      0 NaN\n",
       "2                fkin depressed gonna feeling like this      1 NaN\n",
       "3      when have anxiety every pleasure guilty pleasure      0 NaN\n",
       "4     sorry canxexxt talk right ixexxm doing girl sh...      1 NaN\n",
       "...                                                 ...    ...  ..\n",
       "7693                                    that frequently      0 NaN\n",
       "7694  counterargument krugman predicted great depres...      1 NaN\n",
       "7695  think dignity overrated that status doled limi...      1 NaN\n",
       "7696  cant make depression disappear over night sure...      0 NaN\n",
       "7697  bwhen depression strikes itll weak your bonent...      1 NaN\n",
       "\n",
       "[7698 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"LargeDataset.xlsx\")\n",
    "df['text'].dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a6904ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going through depression open this thread</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fivebalanceusa good afternoon would honored to...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fkin depressed gonna feeling like this</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when have anxiety every pleasure guilty pleasure</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sorry canxexxt talk right ixexxm doing girl sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>that frequently</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>counterargument krugman predicted great depres...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>think dignity overrated that status doled limi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>cant make depression disappear over night sure...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>bwhen depression strikes itll weak your bonent...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    \n",
       "0             going through depression open this thread      1 NaN\n",
       "1     fivebalanceusa good afternoon would honored to...      0 NaN\n",
       "2                fkin depressed gonna feeling like this      1 NaN\n",
       "3      when have anxiety every pleasure guilty pleasure      0 NaN\n",
       "4     sorry canxexxt talk right ixexxm doing girl sh...      1 NaN\n",
       "...                                                 ...    ...  ..\n",
       "7693                                    that frequently      0 NaN\n",
       "7694  counterargument krugman predicted great depres...      1 NaN\n",
       "7695  think dignity overrated that status doled limi...      1 NaN\n",
       "7696  cant make depression disappear over night sure...      0 NaN\n",
       "7697  bwhen depression strikes itll weak your bonent...      1 NaN\n",
       "\n",
       "[7698 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing emojis\n",
    "df[\"text\"]=df[\"text\"].astype(str)\n",
    "df[\"text\"]=df[\"text\"].apply(emoji.demojize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55a76f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going through depression open this thread</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fivebalanceusa good afternoon would honored to...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fkin depressed gonna feeling like this</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when have anxiety every pleasure guilty pleasure</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sorry canxexxt talk right ixexxm doing girl sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>that frequently</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>counterargument krugman predicted great depres...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>think dignity overrated that status doled limi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>cant make depression disappear over night sure...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>bwhen depression strikes itll weak your bonent...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    \n",
       "0             going through depression open this thread      1 NaN\n",
       "1     fivebalanceusa good afternoon would honored to...      0 NaN\n",
       "2                fkin depressed gonna feeling like this      1 NaN\n",
       "3      when have anxiety every pleasure guilty pleasure      0 NaN\n",
       "4     sorry canxexxt talk right ixexxm doing girl sh...      1 NaN\n",
       "...                                                 ...    ...  ..\n",
       "7693                                    that frequently      0 NaN\n",
       "7694  counterargument krugman predicted great depres...      1 NaN\n",
       "7695  think dignity overrated that status doled limi...      1 NaN\n",
       "7696  cant make depression disappear over night sure...      0 NaN\n",
       "7697  bwhen depression strikes itll weak your bonent...      1 NaN\n",
       "\n",
       "[7698 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing URls\n",
    "df[\"text\"] = df[\"text\"].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9478fc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going through depression open this thread</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good afternoon would took look project</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depressed feeling like this</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when have anxiety every pleasure guilty pleasure</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sorry talk right doing girl laundry depressed</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>that frequently</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>counterargument great depression march dead sq...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>think dignity that status limited supply shame...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>cant make depression disappear over night sure...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>depression weak your exactly what watch story</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    \n",
       "0             going through depression open this thread      1 NaN\n",
       "1                good afternoon would took look project      0 NaN\n",
       "2                           depressed feeling like this      1 NaN\n",
       "3      when have anxiety every pleasure guilty pleasure      0 NaN\n",
       "4         sorry talk right doing girl laundry depressed      1 NaN\n",
       "...                                                 ...    ...  ..\n",
       "7693                                    that frequently      0 NaN\n",
       "7694  counterargument great depression march dead sq...      1 NaN\n",
       "7695  think dignity that status limited supply shame...      1 NaN\n",
       "7696  cant make depression disappear over night sure...      0 NaN\n",
       "7697      depression weak your exactly what watch story      1 NaN\n",
       "\n",
       "[7698 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing non english words\n",
    "words = set(nltk.corpus.words.words())\n",
    "def removeNonEng(sent):\n",
    "    k=\" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
    "    if w.lower() in words or not w.isalpha())\n",
    "    return k\n",
    "\n",
    "df[\"text\"]=df[\"text\"].apply(removeNonEng)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fde1aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going through depression open this thread</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good afternoon would took look project</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depressed feeling like this</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when have anxiety every pleasure guilty pleasure</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sorry talk right doing girl laundry depressed</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>that frequently</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>counterargument great depression march dead sq...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7695</th>\n",
       "      <td>think dignity that status limited supply shame...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696</th>\n",
       "      <td>cant make depression disappear over night sure...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7697</th>\n",
       "      <td>depression weak your exactly what watch story</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label    \n",
       "0             going through depression open this thread      1 NaN\n",
       "1                good afternoon would took look project      0 NaN\n",
       "2                           depressed feeling like this      1 NaN\n",
       "3      when have anxiety every pleasure guilty pleasure      0 NaN\n",
       "4         sorry talk right doing girl laundry depressed      1 NaN\n",
       "...                                                 ...    ...  ..\n",
       "7693                                    that frequently      0 NaN\n",
       "7694  counterargument great depression march dead sq...      1 NaN\n",
       "7695  think dignity that status limited supply shame...      1 NaN\n",
       "7696  cant make depression disappear over night sure...      0 NaN\n",
       "7697      depression weak your exactly what watch story      1 NaN\n",
       "\n",
       "[7698 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords\n",
    "stop_words= stopwords.words('english')\n",
    "personal_pronouns= ['i', 'you', 'she', 'he', 'they'] #keeping personal pronouns to serve as a feature\n",
    "\n",
    "for word in personal_pronouns:\n",
    "    if word in stop_words:\n",
    "        stop_words.remove(word)\n",
    "\n",
    "df[\"text\"].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23407b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing natural language\n",
    "X=df[\"text\"]\n",
    "y=df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95ddee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6738b203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8963477357706689\n",
      "Precision: 0.88934034416826\n",
      "Recall: 0.8555989882731663\n",
      "F1 score: 0.8721434431032462\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c331ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9120507685916078\n",
      "Precision: 0.8107365792759051\n",
      "Recall: 0.7466084157277535\n",
      "F1 score: 0.7773521666267657\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80ea9c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9211593269630245\n",
      "Precision: 0.8097345132743363\n",
      "Recall: 0.7994941365831225\n",
      "F1 score: 0.804581742450538\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07e4be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.939948815953469\n",
      "Precision: 0.8739798367738838\n",
      "Recall: 0.8372039549321683\n",
      "F1 score: 0.8551967116852613\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b20e7cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9403071873701704\n",
      "Precision: 0.8759635599159075\n",
      "Recall: 0.862267187859278\n",
      "F1 score: 0.8690614136732329\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b45f1768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\varun sovani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\users\\varun sovani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\layers\\regularization\\dropout.py:42: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">278,720</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │         \u001b[38;5;34m278,720\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m21\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">278,741</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m278,741\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">278,741</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m278,741\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cnn\n",
    "from tensorflow.python.keras import regularizers\n",
    "input_dim = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(20, input_dim=input_dim, activation='relu')) #kernel_regularizer=l2(0.01)\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "205fbb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 0.4223 - val_accuracy: 0.9041 - val_loss: 0.2601\n",
      "Epoch 2/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9235 - loss: 0.2183 - val_accuracy: 0.9113 - val_loss: 0.2381\n",
      "Epoch 3/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9395 - loss: 0.1727 - val_accuracy: 0.9112 - val_loss: 0.2392\n",
      "Epoch 4/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9513 - loss: 0.1410 - val_accuracy: 0.9091 - val_loss: 0.2508\n",
      "Epoch 5/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9578 - loss: 0.1201 - val_accuracy: 0.9103 - val_loss: 0.2596\n",
      "Epoch 6/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9641 - loss: 0.1059 - val_accuracy: 0.9085 - val_loss: 0.2714\n",
      "Epoch 7/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.0943 - val_accuracy: 0.9086 - val_loss: 0.2869\n",
      "Epoch 8/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0828 - val_accuracy: 0.9078 - val_loss: 0.3085\n",
      "Epoch 9/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9761 - loss: 0.0743 - val_accuracy: 0.9059 - val_loss: 0.3251\n",
      "Epoch 10/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0690 - val_accuracy: 0.9073 - val_loss: 0.3379\n",
      "Epoch 11/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0623 - val_accuracy: 0.9041 - val_loss: 0.3618\n",
      "Epoch 12/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0561 - val_accuracy: 0.9052 - val_loss: 0.3841\n",
      "Epoch 13/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9838 - loss: 0.0545 - val_accuracy: 0.9025 - val_loss: 0.4000\n",
      "Epoch 14/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0526 - val_accuracy: 0.9023 - val_loss: 0.4214\n",
      "Epoch 15/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9858 - loss: 0.0466 - val_accuracy: 0.8989 - val_loss: 0.4475\n",
      "Epoch 16/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0446 - val_accuracy: 0.9017 - val_loss: 0.4613\n",
      "Epoch 17/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0427 - val_accuracy: 0.9027 - val_loss: 0.4703\n",
      "Epoch 18/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.0409 - val_accuracy: 0.9000 - val_loss: 0.4925\n",
      "Epoch 19/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9877 - loss: 0.0397 - val_accuracy: 0.9010 - val_loss: 0.5109\n",
      "Epoch 20/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0363 - val_accuracy: 0.9000 - val_loss: 0.5312\n",
      "Epoch 21/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9877 - loss: 0.0373 - val_accuracy: 0.8967 - val_loss: 0.5431\n",
      "Epoch 22/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 0.0353 - val_accuracy: 0.8973 - val_loss: 0.5550\n",
      "Epoch 23/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0340 - val_accuracy: 0.8980 - val_loss: 0.5773\n",
      "Epoch 24/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0324 - val_accuracy: 0.8973 - val_loss: 0.5920\n",
      "Epoch 25/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0311 - val_accuracy: 0.8985 - val_loss: 0.6050\n",
      "Epoch 26/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0317 - val_accuracy: 0.8985 - val_loss: 0.6190\n",
      "Epoch 27/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0319 - val_accuracy: 0.8978 - val_loss: 0.6356\n",
      "Epoch 28/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0301 - val_accuracy: 0.8988 - val_loss: 0.6588\n",
      "Epoch 29/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0314 - val_accuracy: 0.8951 - val_loss: 0.6629\n",
      "Epoch 30/30\n",
      "\u001b[1m1605/1605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0290 - val_accuracy: 0.8963 - val_loss: 0.6812\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d52d97b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Accuracy: 0.9563024511840465\n",
      "Precision: 0.9489759171730813\n",
      "Recall: 0.8973258220280524\n",
      "F1 score: 0.8980527752502275\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.flatten()\n",
    "y_pred = (y_pred>0.5).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce5f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\varun sovani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\users\\varun sovani\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
"Accuracy: 0.9643234220212524\n"

     ]
    }
   ],
   "source": [
    "#BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', cache_dir=\"./\")\n",
    "encoded_data = tokenizer.batch_encode_plus(df[\"text\"].values, add_special_tokens=True, return_attention_mask=True, pad_to_max_length=True, max_length=256, return_tensors='pt')\n",
    "input_ids = encoded_data['input_ids']\n",
    "attention_masks = encoded_data['attention_mask']\n",
    "labels = torch.tensor(df.label.values)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, output_attentions=False, output_hidden_states=False, cache_dir=\"./\")\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i in range(0, input_ids.size(0), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids[i:i+batch_size], attention_mask=attention_masks[i:i+batch_size], labels=labels[i:i+batch_size])\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_masks)\n",
    "    predictions = torch.argmax(outputs[0], dim=1).flatten()\n",
    "    accuracy = torch.sum(predictions == labels) / len(labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f731277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
